{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRayUqtRuL5N1mUIMmU/gP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonalisanjeevprabu18/Neural-Network-and-Deep-Learning/blob/main/Spam_mail_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_IJbodmjv53",
        "outputId": "941d0f2f-3e22-4d42-8827-61aae45ed942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model... (this may take a moment)\n",
            "Test Accuracy: 0.9817\n",
            "Email: Congratulations! You have won a free lottery. Click here to claim your prize.\n",
            "Spam score: 0.9397\n",
            "Prediction: SPAM\n",
            "--------------------------------------------------\n",
            "Email: Hi, this is your manager can we have a meeting at 6pm?\n",
            "Spam score: 0.9443\n",
            "Prediction: SPAM\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "\n",
        "# Data Loading\n",
        "df = pd.read_csv('spam_or_not_spam.csv')\n",
        "df['email'] = df['email'].fillna('')\n",
        "\n",
        "X = df['email'].values\n",
        "y = df['label'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Tokenization\n",
        "VOCAB_SIZE = 10000\n",
        "MAX_LEN = 100\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token='<oov>')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "testing_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_padded = pad_sequences(training_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "X_test_padded = pad_sequences(testing_sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "\n",
        "# Model (Improved)\n",
        "model = Sequential([\n",
        "    Embedding(VOCAB_SIZE, 32, input_length=MAX_LEN), # Increased embedding size\n",
        "    Bidirectional(LSTM(32)),                         # Changed to Bidirectional\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Training (Silent)\n",
        "print(\"Training model... (this may take a moment)\")\n",
        "history = model.fit(\n",
        "    X_train_padded, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_padded, y_test),\n",
        "    verbose=0 # Hides the output table\n",
        ")\n",
        "\n",
        "# Evaluation\n",
        "loss, accuracy = model.evaluate(X_test_padded, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Spam Score + Prediction\n",
        "def get_spam_score_and_prediction(emails):\n",
        "    # Pre-processing: Ensure input matches training format (lowercase)\n",
        "    cleaned_emails = [e.lower() for e in emails]\n",
        "    seq = tokenizer.texts_to_sequences(cleaned_emails)\n",
        "    pad = pad_sequences(seq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "    probs = model.predict(pad, verbose=0)\n",
        "    preds = (probs >= 0.5).astype(int)\n",
        "\n",
        "    for i, email in enumerate(emails):\n",
        "        print(f\"Email: {email}\")\n",
        "        print(f\"Spam score: {probs[i][0]:.4f}\")\n",
        "        print(f\"Prediction: {'SPAM' if preds[i][0] == 1 else 'NOT SPAM'}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "# Test\n",
        "new_emails = [\n",
        "    \"Congratulations! You have won a free lottery. Click here to claim your prize.\",\n",
        "    \"Hi, this is your manager can we have a meeting at 6pm?\"\n",
        "]\n",
        "\n",
        "get_spam_score_and_prediction(new_emails)"
      ]
    }
  ]
}